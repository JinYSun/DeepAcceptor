{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc9c84b",
   "metadata": {},
   "source": [
    "# DeepAcceptorï¼šComputational design and screening of acceptor materials for organic solar cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf8b2d",
   "metadata": {},
   "source": [
    "It is a time-consuming and costly process to developing affordable and high-performance organic photovoltaic materials. Developing reliable computational methods to predict the power conversion efficiency (PCE) is crucial to triage unpromising molecules in large-scale database and accelerate the material discovery process. In this study, a deep-learning based framework (DeepAcceptor) has been built to design and discover high-efficient small molecule acceptor materials. Specifically, an experimental dataset was built by collecting data from publications. Then, a BERT-based model was used to predict PCEs. The molecular graph was used as the input and the computation molecules and experimental molecules were used to pretrain and finetune the model, respectively. DeepAcceptor is a promising method to predict the PCE and speed up the discovery of high-performance acceptor materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50634fca",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cadee2",
   "metadata": {},
   "source": [
    "The atom types and bond information were calculated by using rdkit.The training,test and validation dataset are preprocess by runing the utils .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5779cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdchem\n",
    "\n",
    "from compound_constants import DAY_LIGHT_FG_SMARTS_LIST\n",
    "\n",
    "\n",
    "from utils import mol_to_geognn_graph_data_MMFF3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07941952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    import pandas as pd \n",
    "    from tqdm import tqdm\n",
    "    f = pd.read_csv (r\"data/reg/train0.csv\")\n",
    "    re = []\n",
    "    pce = f['PCE']\n",
    "    for ind,smile in enumerate ( f.iloc[:,1]):\n",
    "        \n",
    "        atom,adj = mol_to_geognn_graph_data_MMFF3d(smile)\n",
    "        np.save('data/reg/train/adj'+str(ind)+'.npy',np.array(adj))\n",
    "        re.append([atom,'data/reg/train/adj'+str(ind)+'.npy',pce[ind] ])\n",
    "    r = pd.DataFrame(re)\n",
    "    r.to_csv('data/reg/train/train.csv')\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d59115",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d7307f",
   "metadata": {},
   "source": [
    "## Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58579150",
   "metadata": {},
   "source": [
    "First, the  masked language model (MLM) task  was chosen as the SMILES was converted into molecular graph by using RDKit. Then, a supernode was added, which was made to connected to all the atoms in a molecule. A mask atoms model was used to pretrain the model similar to MLM task in NLP. As shown in Figure 1, the pretrained model consisting of the embedding layer, transformer encoder layers and classification layers was used to predict the masked atoms. The computational molecules were represented as embeddings including word token embeddings and positional embeddings. Then the embedding was used as the input of transformer encoder layers. Specifically, 15% of the atoms in a molecule were randomly selected, and these atoms have an 80% probability of being represented as [MASK], 10% probability of being replaced by other atoms and 10% probability of keeping unchanged. In pretraining stage, the classification linear layers were added to the transformer encoder layers and used to predict the masked atoms. The original molecules were used as the truth to train the model and predict the types of masked atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0109f8d",
   "metadata": {},
   "source": [
    "### It is recommended to calculate on the supercomputing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18600959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fdfb2",
   "metadata": {},
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35032f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb133d98",
   "metadata": {},
   "source": [
    "The pre-trained model can be used to predict PCE for new NFA materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef66dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "    result =[]\n",
    "    r2_list = []\n",
    "    for seed in [24]:\n",
    "        print(seed)\n",
    "        r2 ,prediction_val,prediction_test= main(seed)\n",
    "        result.append(prediction_val)\n",
    "        r2_list.append(r2)\n",
    "    print(r2_list)\n",
    "    from sklearn.metrics import median_absolute_error,r2_score,mean_squared_error\n",
    "    from scipy.stats import pearsonr\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    re = []\n",
    "    for i in range (len(result)):\n",
    "        data = result[i]\n",
    "        mae = median_absolute_error(data[0],data[1])\n",
    "        r2=r2_score(data[0],data[1])\n",
    "        mse = mean_squared_error(data[0],data[1])\n",
    "        \n",
    "        r=pearsonr(data[0],data[1])[0]\n",
    "        res=np.vstack((mae,r2,mse,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9268bec",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcaf781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd77adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    result =[]\n",
    "    r2_list = []\n",
    "    for seed in [24]:\n",
    "        print(seed)\n",
    "        r2 ,prediction_val= main(seed)\n",
    "        result.append(prediction_val)\n",
    "        r2_list.append(r2)\n",
    "    print(r2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e610c",
   "metadata": {},
   "source": [
    "## Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325417d",
   "metadata": {},
   "source": [
    "Jinyu Sun \n",
    "\n",
    "E-mail: jinyusun@csu.edu.cn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
