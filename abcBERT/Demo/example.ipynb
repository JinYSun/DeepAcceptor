{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bc9c84b",
   "metadata": {},
   "source": [
    "# DeepAcceptorï¼šDeep learning-based design and screening of non-fullerene acceptor materials for organic solar cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf8b2d",
   "metadata": {},
   "source": [
    "It is a time-consuming and costly process to develop affordable and high-performance organic photovoltaic materials. Developing reliable computational methods to predict the power conversion efficiency (PCE) is crucial to triage unpromising molecules in large-scale databases and accelerate the material discovery process. In this study, a deep learning-based framework (DeepAcceptor) has been built to design and discover high-efficient small molecule acceptor materials. Specifically, an experimental dataset was constructed by collecting data from publications. Then, a BERT-based model was customized to predict PCEs by taking fully advantages of the atom, bond, connection information in molecular structures of acceptors, and this customized architecture is termed as abcBERT. The computation molecules and experimental molecules were used to pre-train and fine-tune the model, respectively. The molecular graph was used as the input and the computation molecules and experimental molecules were used to pretrain and finetune the model, respectively. \n",
    "DeepAcceptor is a promising method to predict the PCE and speed up the discovery of high-performance acceptor materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad1c6a",
   "metadata": {},
   "source": [
    "It's a toy data example for the whole process. \n",
    "It was used to test that the code works. \n",
    "All parameters were set small to show how the abcBERT worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50634fca",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cadee2",
   "metadata": {},
   "source": [
    "The atom types and bond information were calculated by using rdkit.The training,test and validation dataset are preprocess by runing the utils .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5779cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdchem\n",
    "\n",
    "from compound_constants import DAY_LIGHT_FG_SMARTS_LIST\n",
    "\n",
    "\n",
    "from utils import mol_to_geognn_graph_data_MMFF3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07941952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "    import pandas as pd \n",
    "    from tqdm import tqdm\n",
    "    f = pd.read_csv (r\"data/reg/train.csv\")\n",
    "    re = []\n",
    "    pce = f['PCE']\n",
    "    for ind,smile in enumerate ( f.iloc[:,1]):\n",
    "        \n",
    "        atom,adj = mol_to_geognn_graph_data_MMFF3d(smile)\n",
    "        np.save('data/reg/train/adj'+str(ind)+'.npy',np.array(adj))\n",
    "        re.append([atom,'data/reg/train/adj'+str(ind)+'.npy',pce[ind] ])\n",
    "    r = pd.DataFrame(re)\n",
    "    r.to_csv('data/reg/train/train.csv')\n",
    "    print('done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24be63ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "    f = pd.read_csv (r\"data/reg/test.csv\")\n",
    "    re = []\n",
    "    pce = f['PCE']\n",
    "    for ind,smile in enumerate ( f.iloc[:,1]):\n",
    "        \n",
    "        atom,adj = mol_to_geognn_graph_data_MMFF3d(smile)\n",
    "        np.save('data/reg/test/adj'+str(ind)+'.npy',np.array(adj))\n",
    "        re.append([atom,'data/reg/test/adj'+str(ind)+'.npy',pce[ind] ])\n",
    "    r = pd.DataFrame(re)\n",
    "    r.to_csv('data/reg/test/test.csv')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c444e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "        f = pd.read_table ('data/chem1.txt')\n",
    "        re = []\n",
    "        for ind,smile in enumerate ( f.iloc[:,0]):\n",
    "            print(ind)\n",
    "            atom,adj = mol_to_geognn_graph_data_MMFF3d(smile)\n",
    "            np.save('data//adj/'+str(ind)+'.npy',np.array(adj))\n",
    "            re.append([atom,'data/adj/'+str(ind)+'.npy'])\n",
    "            r = pd.DataFrame(re)\n",
    "            r.to_csv('data/adj/re.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7307f",
   "metadata": {},
   "source": [
    "## Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58579150",
   "metadata": {},
   "source": [
    "First, the  masked language model (MLM) task  was chosen as the SMILES was converted into molecular graph by using RDKit. Then, a supernode was added, which was made to connected to all the atoms in a molecule. A mask atoms model was used to pretrain the model similar to MLM task in NLP. As shown in Figure 1, the pretrained model consisting of the embedding layer, transformer encoder layers and classification layers was used to predict the masked atoms. The computational molecules were represented as embeddings including word token embeddings and positional embeddings. Then the embedding was used as the input of transformer encoder layers. Specifically, 15% of the atoms in a molecule were randomly selected, and these atoms have an 80% probability of being represented as [MASK], 10% probability of being replaced by other atoms and 10% probability of keeping unchanged. In pretraining stage, the classification linear layers were added to the transformer encoder layers and used to predict the masked atoms. The original molecules were used as the truth to train the model and predict the types of masked atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0109f8d",
   "metadata": {},
   "source": [
    "### It is recommended to calculate on the supercomputing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18600959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6bb33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.7081\n",
      "Accuracy: 0.0000\n",
      "Test Accuracy: 0.0000\n",
      "medium_weights/bert_weightsMedium_1.h5\n",
      "Epoch 1 Loss 0.7081\n",
      "Time taken for 1 epoch: 0.8134782314300537 secs\n",
      "\n",
      "Accuracy: 0.0000\n",
      "Saving checkpoint\n",
      "Epoch 2 Batch 0 Loss nan\n",
      "Accuracy: 0.0000\n",
      "Test Accuracy: 0.0000\n",
      "medium_weights/bert_weightsMedium_2.h5\n",
      "Epoch 2 Loss nan\n",
      "Time taken for 1 epoch: 0.3538072109222412 secs\n",
      "\n",
      "Accuracy: 0.0000\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "pretrain.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fdfb2",
   "metadata": {},
   "source": [
    "The pretrained model can be used to finetune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d35032f",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb133d98",
   "metadata": {},
   "source": [
    "The pre-trained model can be used to predict PCE for new NFA materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ef66dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7200f1ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "data\n",
      "load_wieghts\n",
      "best r2: 0.1220\n",
      "best r2: 0.1220\n",
      "stopping_monitor: 1\n",
      "The model has been trained\n",
      "[0.122]\n"
     ]
    }
   ],
   "source": [
    "    result =[]\n",
    "    r2_list = []\n",
    "    for seed in [24]:\n",
    "        print(seed)\n",
    "        r2 ,prediction_val,prediction_test= regression.main(seed)\n",
    "        result.append(prediction_val)\n",
    "        r2_list.append(r2)\n",
    "    print(r2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9268bec",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f9741",
   "metadata": {},
   "source": [
    "Prediction on large scale dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcaf781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict\n",
    "from predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd77adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "finish!  Results can be found in abcBERT/results.csv\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "prediction_val= main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497141b",
   "metadata": {},
   "source": [
    "Prediction for single molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "815597d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predictbysmiles\n",
    "\n",
    "from predictbysmiles import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bccc062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.348401]\n"
     ]
    }
   ],
   "source": [
    "prediction_val = predictbysmiles.main ('CCCCCCCCC1=CC=C(C2(C3=CC=C(CCCCCCCC)C=C3)C3=CC4=C(C=C3C3=C2C2=C(C=C(C5=CC=C(/C=C6/C(=O)C7=C(C=CC=C7)C6=C(C#N)C#N)C6=NSN=C56)S2)S3)C(C2=CC=C(CCCCCCCC)C=C2)(C2=CC=C(CCCCCCCC)C=C2)C2=C4SC3=C2SC(C2=CC=C(/C=C4\\C(=O)C5=C(C=CC=C5)C4=C(C#N)C#N)C4=NSN=C24)=C3)C=C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e610c",
   "metadata": {},
   "source": [
    "## Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325417d",
   "metadata": {},
   "source": [
    "Jinyu Sun \n",
    "\n",
    "E-mail: jinyusun@csu.edu.cn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
